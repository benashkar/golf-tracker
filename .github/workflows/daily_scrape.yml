name: Daily Golf Data Scrape

on:
  schedule:
    # Run at 6 AM UTC every day (1 AM EST / 2 AM EDT)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allow manual triggers

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run PGA Tour roster scrape
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python -m cli.commands scrape --league PGA --type roster

      - name: Run PGA Tour tournament scrape
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python -m cli.commands scrape --league PGA --type tournaments --year 2025

      - name: Enrich player bios
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python -m cli.commands enrich-bios --limit 50

      - name: Notify on failure
        if: failure()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data '{"text":"⚠️ Golf Tracker daily scrape failed! Check GitHub Actions for details."}' \
              $SLACK_WEBHOOK_URL
          fi
