name: Daily Golf Data Scrape

# ============================================================================
# GOLF TRACKER - DAILY AUTOMATED SCRAPING
# ============================================================================
# This workflow runs daily to scrape golf data from all configured leagues.
# It fetches:
#   - Player rosters (name, country)
#   - Tournament schedules and results (with round-by-round scores)
#   - Player biographical data (high school, hometown, college) from Wikipedia
#
# Currently Supported Leagues:
#   - PGA Tour (GraphQL API)
#   - Korn Ferry Tour (GraphQL API)
#   - PGA Tour Champions (GraphQL API)
#   - LPGA Tour (ESPN API)
#
# To add a new league, see the project documentation in GOLF_TRACKER_PROJECT.md
# ============================================================================

on:
  schedule:
    # Run 3 times daily to catch live tournament updates
    # 6 AM UTC (1 AM EST) - Morning scores from previous day
    # 2 PM UTC (9 AM EST) - Early round updates
    # 10 PM UTC (5 PM EST) - Late round updates
    - cron: '0 6 * * *'
    - cron: '0 14 * * *'
    - cron: '0 22 * * *'
  workflow_dispatch:  # Allow manual triggers from GitHub UI
    inputs:
      year:
        description: 'Year to scrape (default: current year)'
        required: false
        type: string

env:
  # Default to current year, can be overridden by workflow_dispatch input
  SCRAPE_YEAR: ${{ github.event.inputs.year || '' }}

jobs:
  scrape-all-leagues:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ========================================================================
      # MAIN SCRAPE - All leagues at once
      # ========================================================================
      - name: Scrape all leagues (rosters, tournaments, results)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          if [ -n "$SCRAPE_YEAR" ]; then
            python -m cli.commands scrape-all --year $SCRAPE_YEAR
          else
            python -m cli.commands scrape-all
          fi

      # ========================================================================
      # BIO ENRICHMENT - Wikipedia data
      # ========================================================================
      - name: Enrich player bios from Wikipedia
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python -m cli.commands enrich-bios --limit 100

      # ========================================================================
      # SUMMARY - Show database stats
      # ========================================================================
      - name: Show database statistics
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python -m cli.commands stats
        continue-on-error: true

      # ========================================================================
      # NOTIFICATIONS
      # ========================================================================
      - name: Notify on failure
        if: failure()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data "{\"text\":\"⚠️ Golf Tracker daily scrape failed! Check GitHub Actions for details: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"}" \
              $SLACK_WEBHOOK_URL
          fi

  # ============================================================================
  # INDIVIDUAL LEAGUE SCRAPES (can be run separately if needed)
  # ============================================================================
  scrape-pga:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.league == 'PGA' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Scrape PGA Tour
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m cli.commands scrape --league PGA --type roster
          python -m cli.commands scrape --league PGA --type tournaments

  scrape-kornferry:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.league == 'KORNFERRY' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Scrape Korn Ferry Tour
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m cli.commands scrape --league KORNFERRY --type roster
          python -m cli.commands scrape --league KORNFERRY --type tournaments

  scrape-champions:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.league == 'CHAMPIONS' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Scrape Champions Tour
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m cli.commands scrape --league CHAMPIONS --type roster
          python -m cli.commands scrape --league CHAMPIONS --type tournaments

  scrape-lpga:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.league == 'LPGA' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Scrape LPGA Tour
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python -m cli.commands scrape --league LPGA --type roster
          python -m cli.commands scrape --league LPGA --type tournaments
